{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is a groovy example of dealing with big catalogs using Pandas.** Here's what it does:\n",
    "* Read the 3D-HST master catalog\n",
    "* Filter to a subset of galaxies with given stellar mass and redshift.\n",
    "* Read in Arjen's catalogs of morphological parameters fit (using Galfit). Concatenate catalogs for each deep field to a single catalog.\n",
    "* Grab structural parameters (R_e and sersic index) from Arjen's catalogs for the selected objects from the 3D-HST master catalog.  This is easy because Arjen and 3D-HST used the same \"phot_ID\" = \"NUMBER\" for each field.  I made a convenience index JRRID that is in common, and unique, between the two tables.  It's just field + ID.\n",
    "* Plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import seaborn as sns\n",
    "from astropy.io import ascii\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.stats import mad_std\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Failed]\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error timed out>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a3db93ef6172>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read the 3D-HST master catalog.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http://monoceros.astro.yale.edu/RELEASE_V4.1.5/3dhst.v4.1.5.master.fits.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmastercat_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"3dhst.v4.1.5.master.fits.gz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpmcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmastercat_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Note, an endian-ness mismatch between FITS and numpy can cause\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Apps_and_Docs/JRR_Utils/anaconda/lib/python2.7/site-packages/astropy/utils/data.pyc\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(remote_url, cache, show_progress, timeout)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;31m# way, but for some reason in mysterious circumstances it doesn't. So\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0;31m# we'll just re-raise it here instead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlocal_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error timed out>"
     ]
    }
   ],
   "source": [
    "# Read the 3D-HST master catalog.\n",
    "download_file(\"http://monoceros.astro.yale.edu/RELEASE_V4.1.5/3dhst.v4.1.5.master.fits.gz\")\n",
    "mastercat_file = \"3dhst.v4.1.5.master.fits.gz\"\n",
    "pmcat = Table.read(mastercat_file).to_pandas()\n",
    "# Note, an endian-ness mismatch between FITS and numpy can cause\n",
    "# gruesome errrors if you import this WRONG way:\n",
    "#   (mcat, mcat_hdr) = fits.getdata(mastercat_file, header=True)\n",
    "#   pmcat = pandas.DataFrame.from_records(mcat)\n",
    "# USE .to_pandas() to avoid this.  See https://github.com/astropy/astropy/issues/1156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(pmcat)\n",
    "pandas.set_option('display.max_columns', 500)  # print all columns in .head()\n",
    "pmcat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ipython notebook has nice formatting of pandas.head()\n",
    "pmcat['JRRID'] =  pmcat['field'] + \".\" + pmcat['phot_id'].astype(str)\n",
    "pmcat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Demo some basic filtering.  Not used below.\n",
    "zlo = 2.0\n",
    "zhi = 3.0\n",
    "Mlo = 9.0\n",
    "Mhi = 9.5\n",
    "print pmcat[pmcat['use_phot'].eq(1)].shape   # filter on good photometry\n",
    "print pmcat[pmcat['z_best'].between(zlo,zhi)].shape  # Filter redshift\n",
    "print pmcat[pmcat['lmass'].between(Mlo,Mhi)].shape   # Filter stellar mass\n",
    "filt = pmcat['z_best'].between(zlo,zhi) & pmcat['lmass'].between(Mlo,Mhi) & pmcat['use_phot'].eq(1)\n",
    "print pmcat[filt].shape #all 3 filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in Arjen's catalogs of morphological parameters, for each field\n",
    "#download_file(\"http://www.mpia-hd.mpg.de/homes/vdwel/allfields.tar\")\n",
    "# mkdir VanderWel; cd VanderWel; tar -xvf allfields.tar\n",
    "# I then edited by hand the headers, stripping out the initial \"#  \"\n",
    "vdw_H_files = (\"VanderWel/aegis/aegis_3dhst.v4.1_f125w.galfit\", \"VanderWel/goodss/goodss_3dhst.v4.1_f125w.galfit\", \"VanderWel/cosmos/cosmos_3dhst.v4.1_f125w.galfit\", \"VanderWel/uds/uds_3dhst.v4.1_f125w.galfit\", \"VanderWel/goodsn/goodsn_3dhst.v4.1_f125w.galfit\")\n",
    "vdw_fields = ('aegis', 'goodss', 'cosmos', 'uds', 'goodsn')\n",
    "vdw_df = {}\n",
    "for ii, label in enumerate(vdw_fields):\n",
    "    vdw_df[label] = pandas.read_table(vdw_H_files[ii], delim_whitespace=True, comment=\"#\", header=0)\n",
    "    vdw_df[label]['field'] = vdw_fields[ii]\n",
    "    vdw_df[label]['JRRID'] = vdw_fields[ii] + '.' + vdw_df[label]['NUMBER'].astype(str)\n",
    "vdw_all = pandas.concat(vdw_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vdw_all.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JRRID is field.ID, so should be able to directly compare pandas data frames pmcat and vdw_all.\n",
    "Now, PANDAS MAGIC, I will re-index by JRRID, and then I can filter at will!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pmcat_jrr   = pmcat.set_index('JRRID')\n",
    "vdw_all_jrr= vdw_all.set_index('JRRID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter on redshift and M*\n",
    "zlo = 2.0\n",
    "zhi = 3.0\n",
    "Mlo = 9.0\n",
    "Mhi = 9.5\n",
    "# This filtering works b/c I re-indexed arrays by unique index 'JRRID'. \n",
    "# If I weren't already a fan of pandas, this would sell me.  filt1 and filt2 are filters\n",
    "# created from the first and second catalogs, respectively, and while they have different\n",
    "# shapes, Pandas can do math on them (in this case, boolean and), because their indexes\n",
    "# are in common.  This makes a difficult matching (catalogs of different sizes) easy.\n",
    "filt1 = pmcat_jrr['z_best'].between(zlo,zhi) & pmcat_jrr['lmass'].between(Mlo,Mhi)\n",
    "print pmcat_jrr[filt1].shape #both\n",
    "print vdw_all_jrr[filt1].shape\n",
    "filt2 = vdw_all_jrr['f'].eq(0)   # Filter on a good Galfit fit\n",
    "filt = filt1 & filt2   # Require galaxy in M*/z selection, and a good Galfit\n",
    "print vdw_all_jrr[filt2].shape, \"N with good galfit\"\n",
    "print vdw_all_jrr[filt].shape, \"N with good M*, z, galfit:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a point I want to plot\n",
    "kpc_per_arcsec = 8.085\n",
    "# add in s1110          r_e(\")          n     d(r_e(\"))        d(n)\n",
    "s1110_candelized= (2.3/kpc_per_arcsec, 1.0, 0.3/kpc_per_arcsec, 0.4)   # average over all bands\n",
    "s1110_F160cand = (0.32, 0.68, 0.029, 0.26)   #F160W only, from Table 1 of paper draft\n",
    "def plot_my_point() :\n",
    "    plt.scatter( s1110_candelized[0], s1110_candelized[1], color='k', s=100)\n",
    "    plt.errorbar(s1110_candelized[0],s1110_candelized[1], xerr=s1110_candelized[2],yerr=s1110_candelized[3], ecolor='k')\n",
    "    plt.scatter( s1110_F160cand[0], s1110_F160cand[1], color='r', s=100)\n",
    "    plt.errorbar(s1110_F160cand[0],s1110_F160cand[1], xerr=s1110_F160cand[2],yerr=s1110_F160cand[3], ecolor='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's try the seaborn JointGrid, to add histograms to margins\n",
    "# code borrowed from https://github.com/mwaskom/seaborn/issues/469\n",
    "sns.set(font_scale=2)\n",
    "sns.set_style(\"white\")\n",
    "plotted = vdw_all_jrr[filt]\n",
    "print \"median, mad:\", plotted.re.median()*kpc_per_arcsec, mad_std(plotted.re)*kpc_per_arcsec\n",
    "print \"s1110 R_e, std:\", s1110_F160cand[0]*kpc_per_arcsec, s1110_F160cand[2]*kpc_per_arcsec,\n",
    "g = sns.JointGrid(plotted.re, plotted.n, size=8)\n",
    "g.set_axis_labels(\"effective radius (\\\")\", \"Sersic index\")\n",
    "g.ax_marg_x.hist(plotted.re, bins=np.arange(0, 1.0, 0.05))\n",
    "g.ax_marg_y.hist(plotted.n, bins=np.arange(0, 5, 0.2), orientation=\"horizontal\")\n",
    "g.plot_joint(plt.hexbin, gridsize=40, extent=[0, 1.4, 0, 5], cmap=\"Blues\")\n",
    "plot_my_point()  # cool, I can overplot regular matplotlib commands like scatter, errorbar\n",
    "g.fig.savefig(\"filter_hex.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
